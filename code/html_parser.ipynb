{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '../data/prova_1500/article_0.html'\n",
    "def get_soup(fname):\n",
    "    f = open(fname, 'r')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    f.close()\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup, ret):\n",
    "    title = soup.find('title')\n",
    "    ret['title'] = title.contents[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I'll iterate over the divs with class 'spaceit_pad' that contain some spam containing the value of interest for as that are:\n",
    "\n",
    "* anime_type: Type\n",
    "* number of episodes: Episodes\n",
    "* release and end: Aired\n",
    "* number of members: Members\n",
    "* score: Score\n",
    "* users: (in the same spam of Score)\n",
    "* rank: Ranked\n",
    "* popularity: Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_left_attributes(soup, ret):\n",
    "    divs = soup.find_all('div', {\"class\": \"spaceit_pad\"})\n",
    "    from_interest = ['Episodes:','Aired:','Members:','Ranked:','Popularity:']\n",
    "    for div in divs:\n",
    "        content = div.contents\n",
    "        tag = content[1].contents[0]\n",
    "        if tag=='Score:':\n",
    "            attr= {'itemprop':'ratingValue'}\n",
    "            score = div.find('span', attr)\n",
    "            ret['score'] = float(score.contents[0]) if score is not None else None\n",
    "            attr = {'itemprop':'ratingCount'}\n",
    "            users = div.find('span', attr)\n",
    "            ret['users'] = int(users.contents[0]) if users is not None else None\n",
    "        elif tag == 'Type:':\n",
    "            ret['type'] = content[3].contents[0]\n",
    "        elif tag in from_interest:\n",
    "            val = content[2].strip()\n",
    "            if val.startswith('#'):\n",
    "                val=val[1:]\n",
    "                ret[tag[:-1].lower()] = int(val)\n",
    "            elif tag == 'Aired:':\n",
    "                if 'to' in val:\n",
    "                    start, end = val.split('to')\n",
    "                    start = start.strip()\n",
    "                    start = datetime.strptime(start, '%b %d, %Y')\n",
    "                    end = datetime.strptime(end.strip(), '%b %d, %Y') if '?' not in end.strip() else None\n",
    "                    val = f'start: {start}, end: {end}'\n",
    "                    ret['start_date'] = start\n",
    "                    ret['end_date'] = end\n",
    "                else:\n",
    "                    start = datetime.strptime(val.strip(), '%b %d, %Y')\n",
    "                    ret['start_date'] = start\n",
    "                    ret['end_date'] = None\n",
    "            else:\n",
    "                val = val.replace(',','')\n",
    "                \n",
    "                ret[tag[:-1].lower()] = int(val) if val.isnumeric() else None #Sometimes val can be 'unknown' (i.e. see OnePiece)\n",
    "        #print(div.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining fields are:\n",
    "* **Synopsis** (to save as animeDescription): *String*\n",
    "* **Related Anime** (to save as animeRelated): Extract all the related animes, but only keep unique values and those that have a hyperlink associated to them. *List of strings*.\n",
    "* **Characters** (to save as animeCharacters): *List of strings*.\n",
    "* **Voices** (to save as animeVoices): *List of strings*\n",
    "* **Staff** \n",
    "\n",
    "They are contained in different structures of the right side of the page and will be retrieved in the following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell I'll retrieve the description of the anime (synopsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synopsis(soup, ret):\n",
    "    synopsis = soup.find('p', {'itemprop':'description'}).contents[0]\n",
    "    ret['synopsis'] = synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell I'll retrieve the **distinct** related animes in the page that can be found in the table with class 'anime_detail_related_anime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_animes(soup, ret):\n",
    "    related_animes_table = soup.find('table', {'class': 'anime_detail_related_anime'})\n",
    "    if related_animes_table is None:\n",
    "        print('no related animes')\n",
    "        return\n",
    "    animes = set()\n",
    "    for a in related_animes_table.find_all('a'):\n",
    "        a_cont = a.contents\n",
    "        if len(a_cont) > 0:\n",
    "            animes.add(a_cont[0])\n",
    "\n",
    "    ret['related_anime'] = list(animes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_staff(div, ret):\n",
    "    i = 1\n",
    "    staff = []\n",
    "    for td in div.find_all('td', {'class':'borderClass'}):\n",
    "        if (i)==0:\n",
    "            #print(td)\n",
    "            a, small = td.find_all(['small', 'a'])\n",
    "            staff.append([a.contents[0], small.contents[0].split(',')])\n",
    "\n",
    "        i = (i+1)%2\n",
    "    ret['staff'] = staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the only features of interest are voices and characters and they can be found in the other div of the class \"detail-characters-list clearfix\" and they belong to the same table but in two different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_characters_voices(div, ret):\n",
    "    ret['characters'] = []\n",
    "    ret['voices'] = []\n",
    "    ch_vc = [[], []]\n",
    "    links = list(map(lambda x: x.contents[0], div.find_all('a')))\n",
    "    for tr in div.find_all('tr'):\n",
    "        tds = tr.find_all('td', {'class':'borderClass'})\n",
    "        if len(tds) != 3:\n",
    "            continue\n",
    "\n",
    "        ch = tds[1]\n",
    "        vc = tds[2]\n",
    "        ch_a = ch.find('a')\n",
    "        vc_a = vc.find('a')\n",
    "        if ch_a is not None:\n",
    "            ret['characters'].append(ch_a.contents[0])\n",
    "        if vc_a is not None:\n",
    "            ret['voices'].append(vc_a.contents[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_info(fname):\n",
    "    ret = dict()\n",
    "    soup = get_soup(fname)\n",
    "    get_title(soup, ret)\n",
    "    get_left_attributes(soup, ret)\n",
    "    get_synopsis(soup, ret)\n",
    "    get_related_animes(soup, ret)\n",
    "    divs = soup.find_all('div', {'class':\"detail-characters-list clearfix\"})\n",
    "    if len(divs) == 0:\n",
    "        ret['characters'] = []\n",
    "        ret['voices'] = []\n",
    "    elif len(divs) != 2:\n",
    "        if divs[0].find('h3', {'class':\"h3_characters_voice_actors\"}) is not None:\n",
    "            print('only ch_voices')\n",
    "            get_characters_voices(divs[0], ret)\n",
    "            ret['staff'] = []\n",
    "        else:\n",
    "            print('only staff')\n",
    "            get_staff(divs[0], ret)\n",
    "            ret['characters'] = []\n",
    "            ret['voices'] = []\n",
    "    else:\n",
    "        get_characters_voices(divs[0], ret)\n",
    "        get_staff(divs[1], ret)\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Elric, Edward', 'Park, Romi'), ('Elric, Alphonse', 'Kugimiya, Rie'), ('Mustang, Roy', 'Miki, Shinichiro'), ('Hughes, Maes', 'Fujiwara, Keiji'), ('Greed', 'Nakamura, Yuuichi'), ('Hawkeye, Riza', 'Orikasa, Fumiko'), ('Yao, Ling', 'Miyano, Mamoru'), ('Armstrong, Alex Louis', 'Utsumi, Kenji'), ('Rockbell, Winry', 'Takamoto, Megumi'), ('Armstrong, Olivier Mira', 'Soumi, Youko')]\n"
     ]
    }
   ],
   "source": [
    "prova = get_total_info('../data/to8760/article_0.html')\n",
    "print(list(zip(prova['characters'], prova['voices'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join('..', 'data', 'to8760')\n",
    "fnames = sorted(os.listdir(base_dir), key= lambda x: int(x.split('.')[0].split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      "{'title': 'Nurse Witch Komugi-chan R - MyAnimeList.net', 'type': 'TV', 'episodes': 12, 'start_date': datetime.datetime(2016, 1, 10, 0, 0), 'end_date': datetime.datetime(2016, 3, 27, 0, 0), 'score': 5.97, 'users': 3269, 'ranked': 8764, 'popularity': 5052, 'members': 11364, 'synopsis': 'The new \"slapstick\" story will depict Komugi-chan and her rivals as they juggle their daily lives as students, idols, and magical girls \"with laughter and tears.\"', 'related_anime': ['Nurse Witch Komugi-chan Magikarte'], 'characters': ['Yoshida, Komugi', 'Saionji, Kokona', 'Kisaragi, Tsukasa', 'Rei', 'Tamako', 'Misuzu', 'Miki', 'Maki', 'Hime-P', 'Lilia'], 'voices': ['Tomoe, Kei', 'Yamazaki, Erii', 'Koichi, Makoto', 'Matsui, Eriko', 'Kohinata, Akane', 'Maeda, Rena', 'Tachibana, Meemu', 'Asahina, Madoka', 'Momoi, Haruko', 'Satake, Uki'], 'staff': [['Kawaguchi, Keiichirou', ['Director', ' Storyboard']], ['Imaizumi, Yuuichi', ['Sound Director']], ['Fudeyasu, Kazuyuki', ['Script']], ['Murakami, Momoko', ['Script', ' Series Composition']]]}\n"
     ]
    }
   ],
   "source": [
    "print(get_total_info(os.path.join(base_dir, fnames[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      "{'title': 'Bikkuriman Kids: Theme Fighter Nyander - MyAnimeList.net', 'type': 'ONA', 'episodes': 4, 'start_date': datetime.datetime(2008, 8, 6, 0, 0), 'end_date': datetime.datetime(2008, 11, 27, 0, 0), 'score': None, 'users': None, 'ranked': 15007, 'popularity': 16663, 'members': 164, 'synopsis': 'A ', 'related_anime': ['Bikkuriman'], 'characters': [], 'voices': []}\n"
     ]
    }
   ],
   "source": [
    "f_15k = '../data/article_15000.html'\n",
    "print(get_total_info(f_15k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: article_68.html OK!\n",
      "file: article_69.html OK!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Errore nel convertire il value: Unknown del tag Episodes: in intero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-59f99636ee59>\u001b[0m in \u001b[0;36mget_left_attributes\u001b[0;34m(soup, ret)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Unknown'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-0efa04f926c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m68\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mget_total_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"file: {f} OK!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-2e317e62251f>\u001b[0m in \u001b[0;36mget_total_info\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mget_left_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mget_synopsis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mget_related_animes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-59f99636ee59>\u001b[0m in \u001b[0;36mget_left_attributes\u001b[0;34m(soup, ret)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Errore nel convertire il value: {val} del tag {tag} in intero\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Errore nel convertire il value: Unknown del tag Episodes: in intero"
     ]
    }
   ],
   "source": [
    "for f in fnames[68:]:\n",
    "    get_total_info(os.path.join(base_dir, f))\n",
    "    print(f\"file: {f} OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_info_from_idx(idx, base_dir=os.path.join('..', 'data', 'to8760')):\n",
    "    fname = f\"article_{idx}.html\"\n",
    "    return get_total_info(os.path.join(base_dir, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only ch_voices\n",
      "{'title': 'Shiguang Dailiren (Link Click) - MyAnimeList.net', 'type': 'ONA', 'episodes': 11, 'start_date': datetime.datetime(2021, 4, 30, 0, 0), 'end_date': datetime.datetime(2021, 7, 9, 0, 0), 'score': 8.86, 'users': 33258, 'ranked': 23, 'popularity': 1361, 'members': 131580, 'synopsis': 'It is said that a picture is worth a thousand words. In this case, it holds an infinite amount of secrets. These are secrets that only Cheng Xiaoshi and Lu Guang are able to find. In a small shop called \"Time Photo Studio,\" the two friends provide a special service: using their extraordinary powers that let them enter photographs, they jump into pictures brought to them by clients in order to grant their wishes. Through the eyes of the photographer, they live through the events surrounding the picture and try to decipher how to solve their client\\'s request.', 'related_anime': ['Shiguang Dailiren Specials', 'Shiguang Dailiren 2nd Season', 'Shiguang Dailiren Fan Wai Pian: Biwu Zhaoqin'], 'characters': ['Cheng, Xiaoshi', 'Lu, Guang', 'Qiao, Ling', 'Liu, Min', 'Yu, Xia', 'Lin, Zhen'], 'voices': [], 'staff': []}\n"
     ]
    }
   ],
   "source": [
    "print(get_total_info_from_idx(22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e3f86d80f9d4ea2c2a83e8f7b2349235d41b98d2c2cd154f6179deca092a54d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
