{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/prova_1500/article_0.html', 'r')\n",
    "soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fullmetal Alchemist: Brotherhood - MyAnimeList.net'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.find('title')\n",
    "title.contents[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I'll iterate over the divs with class 'spaceit_pad' that contain some spam containing the value of interest for as that are:\n",
    "\n",
    "* anime_type: Type\n",
    "* number of episodes: Episodes\n",
    "* release and end: Aired\n",
    "* number of members: Members\n",
    "* score: Score\n",
    "* users: (in the same spam of Score)\n",
    "* rank: Ranked\n",
    "* popularity: Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      "{'type': 'TV', 'episodes': 64, 'start_date': datetime.datetime(2009, 4, 5, 0, 0), 'end_date': datetime.datetime(2010, 7, 4, 0, 0), 'score': 9.16, 'users': 1622384, 'ranked': 1, 'popularity': 3, 'members': 2675751}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "divs = soup.find_all('div', {\"class\": \"spaceit_pad\"})\n",
    "from_interest = ['Episodes:','Aired:','Members:','Ranked:','Popularity:']\n",
    "ret = dict()\n",
    "for div in divs:\n",
    "    content = div.contents\n",
    "    tag = content[1].contents[0]\n",
    "    if tag=='Score:':\n",
    "        print('Score:')\n",
    "        attr= {'itemprop':'ratingValue'}\n",
    "        ret['score'] = float(div.find('span', attr).contents[0])\n",
    "        attr = {'itemprop':'ratingCount'}\n",
    "        ret['users'] = int(div.find('span', attr).contents[0])\n",
    "    elif tag == 'Type:':\n",
    "        ret['type'] = content[3].contents[0]\n",
    "    elif tag in from_interest:\n",
    "        val = content[2].strip()\n",
    "        if val.startswith('#'):\n",
    "            val=val[1:]\n",
    "            ret[tag[:-1].lower()] = int(val)\n",
    "        elif 'to' in val:\n",
    "            start, end = val.split('to')\n",
    "            start = start.strip()\n",
    "            start = datetime.strptime(start, '%b %d, %Y')\n",
    "            end = datetime.strptime(end.strip(), '%b %d, %Y')\n",
    "            val = f'start: {start}, end: {end}'\n",
    "            ret['start_date'] = start\n",
    "            ret['end_date'] = end\n",
    "        else:\n",
    "            ret[tag[:-1].lower()] = int(val.replace(',',''))\n",
    "print(ret)\n",
    "    #print(div.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining fields are:\n",
    "* **Synopsis** (to save as animeDescription): *String*\n",
    "* **Related Anime** (to save as animeRelated): Extract all the related animes, but only keep unique values and those that have a hyperlink associated to them. *List of strings*.\n",
    "* **Characters** (to save as animeCharacters): *List of strings*.\n",
    "* **Voices** (to save as animeVoices): *List of strings*\n",
    "* **Staff** \n",
    "\n",
    "They are contained in different structures of the right side of the page and will be retrieved in the following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell I'll retrieve the description of the anime (synopsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopsis = soup.find('p', {'itemprop':'description'}).contents[0]\n",
    "ret['synopsis'] = synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell I'll retrieve the **distinct** related animes in the page that can be found in the table with class 'anime_detail_related_anime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_animes_table = soup.find('table', {'class': 'anime_detail_related_anime'})\n",
    "animes = set()\n",
    "for a in related_animes_table.find_all('a'):\n",
    "    animes.add(a.contents[0])\n",
    "\n",
    "list(animes)\n",
    "ret['related_anime'] = list(animes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs = soup.find_all('div', {'class':\"detail-characters-list clearfix\"})\n",
    "i = 1\n",
    "staff = []\n",
    "for td in divs[-1].find_all('td', {'class':'borderClass'}):\n",
    "    if (i)==0:\n",
    "        #print(td)\n",
    "        a, small = td.find_all(['small', 'a'])\n",
    "        staff.append([a.contents[0], small.contents[0].split(',')])\n",
    "\n",
    "    i = (i+1)%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret['staff'] = staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the only features of interest are voices and characters and they can be found in the other div of the class \"detail-characters-list clearfix\" and they belong to the same table but in two different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_vc = [[], []]\n",
    "links = list(map(lambda x: x.contents[0], divs[0].find_all('a')))\n",
    "i = 0\n",
    "        #print(td)\n",
    "for l in links:\n",
    "    if l=='\\n':\n",
    "        continue\n",
    "    ch_vc[i].append(l)\n",
    "    i = (i+1)%2\n",
    "\n",
    "ret['characters'] = ch_vc[0]\n",
    "ret['voices'] = ch_vc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'TV',\n",
       " 'episodes': 64,\n",
       " 'start_date': datetime.datetime(2009, 4, 5, 0, 0),\n",
       " 'end_date': datetime.datetime(2010, 7, 4, 0, 0),\n",
       " 'score': 9.16,\n",
       " 'users': 1622384,\n",
       " 'ranked': 1,\n",
       " 'popularity': 3,\n",
       " 'members': 2675751,\n",
       " 'synopsis': \"After a horrific alchemy experiment goes wrong in the Elric household, brothers Edward and Alphonse are left in a catastrophic new reality. Ignoring the alchemical principle banning human transmutation, the boys attempted to bring their recently deceased mother back to life. Instead, they suffered brutal personal loss: Alphonse's body disintegrated while Edward lost a leg and then sacrificed an arm to keep Alphonse's soul in the physical realm by binding it to a hulking suit of armor.\",\n",
       " 'related_anime': ['Fullmetal Alchemist: The Sacred Star of Milos',\n",
       "  'Fullmetal Alchemist: Brotherhood Specials',\n",
       "  'Fullmetal Alchemist: Brotherhood - 4-Koma Theater',\n",
       "  'Fullmetal Alchemist'],\n",
       " 'staff': [['Cook, Justin', ['Producer']],\n",
       "  ['Yonai, Noritomo', ['Producer']],\n",
       "  ['Irie, Yasuhiro', ['Director', ' Episode Director', ' Storyboard']],\n",
       "  ['Mima, Masafumi', ['Sound Director']]],\n",
       " 'characters': ['Elric, Edward',\n",
       "  'Elric, Alphonse',\n",
       "  'Mustang, Roy',\n",
       "  'Hughes, Maes',\n",
       "  'Greed',\n",
       "  'Hawkeye, Riza',\n",
       "  'Yao, Ling',\n",
       "  'Armstrong, Alex Louis',\n",
       "  'Rockbell, Winry',\n",
       "  'Armstrong, Olivier Mira'],\n",
       " 'voices': ['Park, Romi',\n",
       "  'Kugimiya, Rie',\n",
       "  'Miki, Shinichiro',\n",
       "  'Fujiwara, Keiji',\n",
       "  'Nakamura, Yuuichi',\n",
       "  'Orikasa, Fumiko',\n",
       "  'Miyano, Mamoru',\n",
       "  'Utsumi, Kenji',\n",
       "  'Takamoto, Megumi',\n",
       "  'Soumi, Youko']}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e3f86d80f9d4ea2c2a83e8f7b2349235d41b98d2c2cd154f6179deca092a54d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
